<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Understanding Floating Point Error - website.</title>
<meta name="description" content="Floating point is the most commonly used number format for calculations. In this post, I go over the basics of understanding floating point rounding and error bounds.">


  <meta name="author" content="Nate Armstrong">
  
  <meta property="article:author" content="Nate Armstrong">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="website.">
<meta property="og:title" content="Understanding Floating Point Error">
<meta property="og:url" content="http://localhost:4000/understanding-floating-point-error/">


  <meta property="og:description" content="Floating point is the most commonly used number format for calculations. In this post, I go over the basics of understanding floating point rounding and error bounds.">







  <meta property="article:published_time" content="2020-05-28T04:00:00-07:00">





  

  


<link rel="canonical" href="http://localhost:4000/understanding-floating-point-error/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Nate Armstrong",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="website. Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!-- Include Favicon -->
<link rel="shortcut icon" type="image/png" href="/assets/fav/favi32.png">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          website.
          <span class="site-subtitle">thoughts on math, statistics, and computer science.</span>
        </a>
        <ul class="visible-links"></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="http://localhost:4000/" itemprop="item"><span itemprop="name">Home</span></a>
          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        <li class="current">Understanding Floating Point Error</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/img/profile.jpeg" alt="Nate Armstrong" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Nate Armstrong</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>UC Berkeley Alumni. Software engineer.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Berkeley, CA</span>
        </li>
      

      
        
          
        
          
            <li><a href="https://github.com/naterarmstrong" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/naterarmstrong/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:narmstrong@berkeley.edu">
            <meta itemprop="email" content="narmstrong@berkeley.edu" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Understanding Floating Point Error">
    <meta itemprop="description" content="Floating point is the most commonly used number format for calculations. In this post, I go over the basics of understanding floating point rounding and error bounds.">
    <meta itemprop="datePublished" content="2020-05-28T04:00:00-07:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Understanding Floating Point Error
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 

11 minutes to read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        


	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	    extensions: [
	      "MathMenu.js",
	      "MathZoom.js",
	      "AssistiveMML.js",
	      "a11y/accessibility-menu.js"
	    ],
	    jax: ["input/TeX", "output/CommonHTML"],
	    TeX: {
	      extensions: [
	        "AMSmath.js",
	        "AMSsymbols.js",
	        "noErrors.js",
	        "noUndefined.js",
	      ]
	    }
	  });
	</script>
	<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
        <p>Floating point is the most commonly used number format for calculations.
However, most people donâ€™t know how error is created and propagated in floating point calculations.
In this post, I go over the basics of understanding floating point rounding and error bounds.</p>

<h2 id="floating-point">Floating Point</h2>

<p>There are many explanations of floating point on the internet, and so I will not write a detailed explanation here.
If you do not know what floating point is, I recommend reading the article here(TODO).
For our purposes, we are interested in the IEEE 754 64 bit floating point representation.
I ignore the sign bit, as it is not relevant to error calculations.
Below, I list the breakdown of bits for these representations.</p>

<table>
  <thead>
    <tr>
      <th>Mantissa Length</th>
      <th>Characteristic Length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>52</td>
      <td>11</td>
    </tr>
  </tbody>
</table>

<p>We denote the mantissa by \(m\) of length \(l_m\), the characteristic by \(c\) of length \(l_c\), and the sign bit as \(s\).
The characteristic is <em>biased</em>, which means that the true exponent is given by \(c - 2^{l_c - 1} + 1\), giving us \(2^{l_c - 1}\)
positive characteristics, and \(2^{l_c - 1} - 1\) negative characteristics.
Any number with \(c \neq 0\) and \(m \neq 0\) will be represented as</p>

\[(-1)^s \left(1 + \frac{m}{2^{-52}}\right) \cdot 2^{c - 1023}\]

<p>For example, if we had the number 5.25, we can convert this to floating point.
We first see that this number is between \(4=2^2\) and \(8 = 2^3\), and so \(c - 1023 = 2 \implies c = 1025\).
Then, we see that</p>

\[5.25 = 4 + 1 + .25 = 2^2 + 2^0 + 2^{-2}\]

<p>which gives us the mantissa.</p>

<table>
  <thead>
    <tr>
      <th>Sign</th>
      <th>Mantissa</th>
      <th>Characteristic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>\(\underbrace{0101000\dots}_\text{5$2_{}$ digits}\)</td>
      <td>10000000001</td>
    </tr>
  </tbody>
</table>

<h3 id="machine-epsilon">Machine Epsilon</h3>

<p>We all know that with only 64 bits to represent a number, we can only represent a finite amount of numbers.
In fact, it will certainly be at most \(2^{64}\) numbers.
How far apart are these numbers with the floating point standard?</p>

<p>In fact, it depends on the characteristic of the floating point number.
For every exponent \(-1022 \leq k \leq 1022\), there are exactly \(2^{52}\) numbers between \(2^k\)  and \(2^{k+1}\), one for each possible mantissa.
Note that we are ignoring the largest and smallest exponents here, as those correspond to special floating point numbers.</p>

<p>First, we will consider the numbers \(1 \leq x \leq 2\).
The smallest number we can represent in this range is exactly 1, by letting the characteristic equal 1024 and the mantissa be 0.
The next largest number we can represent in this range is \(1 + 2^{-52}\), by letting the characteristic equal 1024 and the mantissa be
all 0s except for a 1 at the end.
Thus, the difference between these numbers is \(\epsilon = 2^{-52}\). Clearly, successive numbers in this range differ by 1 in the mantissa, which is \(\epsilon\) on the real number line.
We call \(\epsilon\) <em>machine epsilon</em>, to refer to the smallest gap between numbers that the computer can represent in this number format.
However, we have not yet understood if \(\epsilon\) is the smallest gap, or if it is relative to the number represented.</p>

<p>Then, we consider the numbers between 2 and 4. We still have a distance of 1 in the mantissa between successive numbers.
However, now this corresponds to \(2^{-51}\), or \(2\epsilon\). Between 4 and 8, the distance is \(4\epsilon\).
Between 1/2 and 1, the distance is only \(\epsilon / 2\)
By now, the trend should be fairly clear. The distance between successive numbers is relative to the size of the number.
More precisely, the distance from a number \(x\) to the next floating point number is exactly</p>

\[2^{\lfloor \log_2(x) \rfloor} \epsilon.\]

<h2 id="rounding-in-floating-point">Rounding in Floating Point</h2>

<p>We need to introduce some new notation in order to differentiate between a number, \(x\), and its floating point representation,
\(\textbf{fl}(x)\). The representation of a number \(x\) in floating point is just the rounded representation of it.
We round just as we would with an ordinary number.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> The key point of floating point error is understanding the difference between
\(x\) and \(\textbf{fl}(x)\), and how this difference propagates through floating point operations.</p>

<p>For example, if we have \(x = 1 + \frac{\epsilon}{4}\), we round this to \(\textbf{fl}(x) = 1\).
On the other hand, \(\textbf{fl}\left(1 + \frac{3\epsilon}{4}\right) = 1 + \epsilon\).</p>

<h3 id="rounding-error-in-floating-point">Rounding Error in Floating Point</h3>

<p>We know that rounding will introduce some error. We bring a range of numbers to another, simpler number.
How do we quantify this?</p>

<p>Letâ€™s consider rounding \(x\) between 1 and 2. Then, the distance between consecutive floating point numbers is \(\epsilon\).
At worst, a point \(x\) will be \(\frac{\epsilon}{2}\) from \(\textbf{fl}(x)\).
Mathematically, this becomes</p>

\[|x - \textbf{fl}(x)| \leq \frac{\epsilon}{2}\]

<p>In fact, we can divide by  \(\mid x \mid\) on the left side, as we know that \(\mid x\mid\) is between 1 and 2.
The resultant expression is true for all \(x\), as the floating point error scales with \(\mid x\mid\).<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>

\[\frac{|x - \textbf{fl}(x)|}{|x|} \leq \frac{\epsilon}{2}\]

<p>When we want to talk about the error and propagate it, we want a better solution than keeping an awful inequality for every single arithmetic operation.
Thus, we state that \(x - \textbf{fl}(x) = \delta x\) for some \(-\frac{\epsilon}{2} \leq \delta \leq \frac{\epsilon}{2}\).
This can also be written as \(\textbf{fl}(x) = x(1 + \delta)\).
Then, we have an exact expression for \(x\) that makes understanding and propagating these errors through complex floating point expressions and algorithms much more understandable and practical.</p>

<p>Now that we understand how to quantify floating point error when rounding, we need to understand how to apply it to floating point operations.</p>

<h3 id="error-in-floating-point-operations">Error in Floating Point Operations</h3>

<p>Most computers nowadays have dedicated circuits devoted to solving basic floating point operations.
However, in order to understand the error of a floating point operation, we donâ€™t need to understand how these circuits work.
We treat the floating point operation as a black box,
and assume that the result of a floating point operation is the <em>exact result correctly rounded</em>.</p>

<p>To understand what this means, letâ€™s assume that our number representation method can only handle integers, and weâ€™ve implemented division as one of our operations.
Clearly, the result of \(4 / 3\) is not going to be an integer, as it is 1.33.
Thus, we assume that our division operation will find the correct result (1.33) and then round it for a result of 1.
We do this <em>even though we cannot represent 1.33 in this system</em>.</p>

<h3 id="multiple-inputs">Multiple Inputs</h3>

<p>Every basic arithmetic operation is considered to be done in a single floating point operation.
However, it is important to note that the floating point operations can only operate on two inputs at a time, and they are not associative.
Thus, the mathematical expression \(a + b + c\) does not translate to a unique floating point representation.
It could be either
\(\textbf{fl}(\textbf{fl}(a + b) + c)\)
or
\(\textbf{fl}(a + \textbf{fl}(b + c))\)
.</p>

<p>When we look at the actual result of the two operations above, they are <em>not the same</em>.
Also, when we write out the error for multiple operations, we need to keep track of multiple \(\delta\)s, as defined above.
Thus, we number them as we use them.</p>

<table>
  <thead>
    <tr>
      <th>Representation</th>
      <th>Result after the first operation</th>
      <th>Final Result</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>\(\textbf{fl}(\textbf{fl}(a + b) + c)\)</td>
      <td>\(\textbf{fl}((a + b)(1 + \delta_1) + c)\)</td>
      <td>\(((a + b)(1 + \delta_1) + c)(1 + \delta_2)\)</td>
    </tr>
    <tr>
      <td>\(\textbf{fl}(a + \textbf{fl}(b + c))\)</td>
      <td>\(\textbf{fl}(a + (b + c)(1 + \delta_3))\)</td>
      <td>\((a + (b + c)(1 + \delta_3))(1 + \delta_4)\)</td>
    </tr>
  </tbody>
</table>

<p>When we factor out the above expressions to isolate the \(a\)â€™s, \(b\)â€™s, and \(c\)â€™s, we get</p>

\[a(1 + \delta_1)(1 + \delta_2) + b(1 + \delta_1)(1 + \delta_2) + c(1 + \delta_2)\]

<p>and</p>

\[a(1 + \delta_4) + b(1 + \delta_3)(1 + \delta_4) + c(1 + \delta_3)(1 + \delta_4).\]

<p>First, we simplify this by rewriting \(\delta_i + \delta_j\) as 2 multiplied by some other \(\delta\), equal to the average of the two.
Then, we see that terms which are the multiples of two \(\delta\)s are at most absolute value \(\epsilon^2 / 4\), which is small enough to ignore. Thus, we get</p>

\[a(1 + 2\delta_5) + b(1 + 2\delta_5) + c(1 + \delta_2)\]

<p>and</p>

\[a(1 + \delta_4) + b(1 + 2\delta_6) + c(1 + 2\delta_6).\]

<p>We can see that the possible error on each input scales linearly with the number of operations that it is in.
We can also see that the possible error is different for each input. For example, if \(a = 2^{51}\), and \(b = c = 1\), the absolute error bounds would be</p>

<table>
  <thead>
    <tr>
      <th>Expression</th>
      <th style="text-align: center">Error</th>
      <th>Absolute Error Bound</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>\(\textbf{fl}(\textbf{fl}(a + b) + c)\)</td>
      <td style="text-align: center">\(a(1 + 2\delta_5) + b(1 + 2\delta_5) + c(1 + \delta_2)\)</td>
      <td>\(2 + \frac{3\epsilon }{2}\)</td>
    </tr>
    <tr>
      <td>\(\textbf{fl}(a + \textbf{fl}(b + c))\)</td>
      <td style="text-align: center">\(a(1 + \delta_4) + b(1 + 2\delta_6) + c(1 + 2\delta_6)\)</td>
      <td>\(1 + 2\epsilon\)</td>
    </tr>
  </tbody>
</table>

<p>which are very different. The error in the same operation becomes very nearly doubled by the simple change in order of operations!
Of course, this was an extreme example to demonstrate a point, but we will show something more realistic later in a later post.
In general, we want the intermediate sums to be as small as possible. An easy heuristic for this is to add the smallest numbers first, and then the largest.</p>

<p>For the rest of the post, we assume that we did the calculation in the first way, \(((a + b) + c\).
Next, we have to decide how we want to interpret this error.</p>

<h3 id="forward-vs-backwards-error-analysis">Forward vs Backwards Error Analysis</h3>

<p>There are two distinct methods with which to calculate the error of an expression \(\textbf{fl}(f(a, b, c))\)</p>

<ol>
  <li>
    <p><strong>Forwards Error Analysis</strong>: We consider the relative error between the exact result and the floating point result.
This gives us an error expression of</p>

\[\frac{\mid \textbf{fl}(a + b + c) - (a + b + c) \mid }{ \mid a + b + c \mid}\]
  </li>
  <li>
    <p><strong>Backwards Error Analysis</strong>: We consider the result as being the exact correct operation done to almost the correct inputs.
In this case, we get
\(\textbf{fl}(a + b + c) = \hat{a} + \hat{b} + \hat{c}\)
where \(\hat{a} = a(1 + 2\delta_4)\) and so on. Then, we bound how close these inputs are to the actual inputs.
In this case, we would say that</p>

\[\left| \frac{\hat{a} - a}{a} \right| \leq \epsilon.\]
  </li>
</ol>

<p>In this case, it turns out that forward error analysis gives extremely weak bounds. We can construct special inputs to make the relative forward error bound as bad as we want.
The relative error bound will simplify to</p>

\[\frac{2 |a + b| + |c|}{| a + b + c|} \frac{\epsilon}{2}\]

<p>which grows very large if we choose some very small number \(x\), and then let \(a + b = 1\), and \(c = - 1 + x\).
Then, our error bound becomes</p>

\[\frac{3 - x}{x} \frac{\epsilon}{2}\]

<p>which goes to infinity as we let \(x \to 0\).
Thus, this relative error bound is not useful.</p>

<p>Therefore, it is better to use backwards error analysis for this example.
In fact, this is true in general for analyzing floating point error.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The standard for breaking ties in floating point rounding is to <em>round such that the last bit of the result is 0</em>. Clearly, between any two numbers, one will have a last bit 0. This is a different practice than the standard rules of breaking ties by rounding up or down. If we consider rounding up or down, we can see that this would introduce a bias to our floating point calculations: The floating point result of any operation will be less than or equal to the true result if we only round up (or vice versa if we rounded up). By rounding such that the last bit is 0, the symmetry in that operation to that makes this an unbiased operation over random numbers.Â <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>This is slightly imprecise, but you can convince yourself of this by considering the possible errors right around the â€˜breakpointsâ€™ of \(x=1\) and \(x=2\). Then, you can see how this extends to the general breakpoints present at powers of 2.Â <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#computer-science" class="page__taxonomy-item" rel="tag">Computer Science</a><span class="sep">, </span>
    
      <a href="/tags/#math" class="page__taxonomy-item" rel="tag">Math</a>
    
    </span>
  </p>




        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-05-28T04:00:00-07:00">May 28, 2020</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="#" class="pagination--pager disabled">Previous</a>
    
    
      <a href="/floating-point-error-example/" class="pagination--pager" title="Floating Point Error Example
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pick-the-largest-number/" rel="permalink">Guess the Largest Number Paradox
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Many statistical paradoxes boil down to an imprecise problem statement, but this is one paradox that is truly astonishing, where we seem to get information f...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/floating-point-error-example/" rel="permalink">Floating Point Error Example
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Last post, we talked about how to understand floating point error, but the only example we consider was the trivial case of a + b + c. In this post, we will ...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/naterarmstrong" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/naterarmstrong/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Nate Armstrong. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
